{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n",
      "img data fmt:  channels_last\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, save_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.optimizers import SGD\n",
    "from IPython.display import display\n",
    "import keras.utils\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "print('img data fmt: ', K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "# convert target labels from scalars to an array of binary values\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# convert img data from ints in range [0,255] to floats in range [0,1] \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNN(layer_dict, opt=\"sgd\"):\n",
    "    cnn = Sequential()\n",
    "    for key, val in layer_dict.items():\n",
    "        if (key=='CONV_2D'):\n",
    "            cnn.add(Conv2D(filters=val[0], \n",
    "                           kernel_size=val[1], \n",
    "                           input_shape=val[2],\n",
    "                           activation=val[3]))\n",
    "        elif (key=='POOL'):\n",
    "            cnn.add(MaxPooling2D(pool_size=val[0],\n",
    "                                 strides=val[1]))\n",
    "        elif (key=='FLATTEN'):\n",
    "            cnn.add(Flatten())\n",
    "        elif (key=='DENSE'):\n",
    "            cnn.add(Dense(units=val[0],\n",
    "                          activation=val[1]))\n",
    "    \n",
    "    cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeModelData(model, layer_dict, modelName=\"new_model\", out_dir=\"..\\\\..\\\\store\\\\csv\"):\n",
    "    \n",
    "    h5_path = \"..\\\\..\\\\store\\\\saved_models\\\\{}.h5\".format(modelName)\n",
    "    model.save(h5_path)\n",
    "    \n",
    "    nLayers = len(layer_dict.keys())\n",
    "    params = model.count_params()\n",
    "    hyperParams = 0\n",
    "    size_kb = 0\n",
    "    opt=\"sgd\"\n",
    "    \n",
    "    model_df = pd.DataFrame(columns=['name', 'layers', 'params', 'hyperParams',\n",
    "                                     'size_kb', 'filePath', 'optimizer'],\n",
    "                            data = [[modelName, nLayers, params, hyperParams,\n",
    "                                    size_kb, h5_path, opt]])\n",
    "    layer_df = pd.DataFrame(columns=['modelName', 'depth', 'type', 'params', 'filters', 'inputShape',\n",
    "                                     'outputShape','kernelShape', 'strides'],\n",
    "                            index=np.arange(nLayers))\n",
    "    layer_df.loc[:, 'modelName'] = modelName\n",
    "    depth=0\n",
    "    for key, val in layer_dict.items():\n",
    "        layer_df.loc[depth, 'depth'] = depth+1\n",
    "        layer_df.loc[depth, 'type'] = key\n",
    "        layer_df.loc[depth, 'params'] = model.layers[depth].count_params()\n",
    "        layer_df.loc[depth, 'inputShape'] = model.layers[depth].input_shape[1:]\n",
    "        layer_df.loc[depth, 'outputShape'] = model.layers[depth].output_shape[1:]\n",
    "        if (key == 'CONV_2D'):\n",
    "            layer_df.loc[depth, 'filters'] = val[0]\n",
    "            layer_df.loc[depth, 'kernelShape'] = val[1]\n",
    "            layer_df.loc[depth, 'strides'] = (1,1)\n",
    "        elif (key == 'POOL'):\n",
    "            layer_df.loc[depth, 'filters'] = 0\n",
    "            layer_df.loc[depth, 'kernelShape'] = val[0]\n",
    "            layer_df.loc[depth, 'strides'] = val[1]\n",
    "        depth += 1\n",
    "    #display(model_df)\n",
    "    #display(layer_df)\n",
    "    model_df.to_csv(os.path.join(out_dir, \"{}.csv\".format(modelName)),\n",
    "                    header=False)\n",
    "    layer_df.to_csv(os.path.join(out_dir, \"{}_layers.csv\".format(modelName)),\n",
    "                    header=False)\n",
    "    #model_df.iloc[0,:] = [modelName]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28,28,1)\n",
    "\n",
    "layer_dict1 = {'CONV_2D' : [16, (3,3), input_shape, 'relu'],\n",
    "               'POOL'    : [(2,2), (2,2)],\n",
    "               'FLATTEN' : [],\n",
    "               'DENSE'   : [128, 'relu'],\n",
    "               'DENSE'   : [10, 'softmax']}\n",
    "\n",
    "layer_dict2 = {'CONV_2D' : [8, (3,3), input_shape, 'relu'],\n",
    "               'POOL'    : [(2,2), (2,2)],\n",
    "               'FLATTEN' : [],\n",
    "               'DENSE'   : [128, 'relu'],\n",
    "               'DENSE'   : [10, 'softmax']}\n",
    "\n",
    "cnn1 = makeCNN(layer_dict1)\n",
    "cnn2 = makeCNN(layer_dict2)\n",
    "#cnn1.summary()\n",
    "#hist1 = trainCNN(cnn1)\n",
    "writeModelData(cnn1, layer_dict1, \"MNIST_CNN_small\")\n",
    "writeModelData(cnn2, layer_dict2, \"MNIST_CNN_small_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCNN(cnn, ep=10, b_size=128, dataset='MNIST'):\n",
    "    hist = cnn.fit(X_train, y_train, batch_size=b_size, epochs=ep)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
