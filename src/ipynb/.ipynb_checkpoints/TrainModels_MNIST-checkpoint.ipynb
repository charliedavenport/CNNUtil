{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n",
      "img data fmt:  channels_last\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, save_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.optimizers import SGD\n",
    "from IPython.display import display\n",
    "import keras.utils\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "print('img data fmt: ', K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "# convert target labels from scalars to an array of binary values\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# convert img data from ints in range [0,255] to floats in range [0,1] \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "    # convert target labels from scalars to an array of binary values\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    # convert img data from ints in range [0,255] to floats in range [0,1] \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNN(layer_dict, opt=\"sgd\"):\n",
    "    cnn = Sequential()\n",
    "    for key, val in layer_dict.items():\n",
    "        if (key=='CONV_2D'):\n",
    "            cnn.add(Conv2D(filters=val[0], \n",
    "                           kernel_size=val[1], \n",
    "                           input_shape=val[2],\n",
    "                           activation=val[3]))\n",
    "        elif (key=='POOL'):\n",
    "            cnn.add(MaxPooling2D(pool_size=val[0],\n",
    "                                 strides=val[1]))\n",
    "        elif (key=='FLATTEN'):\n",
    "            cnn.add(Flatten())\n",
    "        elif (key=='DENSE'):\n",
    "            cnn.add(Dense(units=val[0],\n",
    "                          activation=val[1]))\n",
    "    \n",
    "    cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeModelData(model, layer_dict, modelName=\"new_model\", out_dir=\"..\\\\..\\\\store\\\\models\"):\n",
    "    \n",
    "    h5_path = \"..\\\\..\\\\store\\\\saved_models\\\\{}.h5\".format(modelName)\n",
    "    model.save(h5_path)\n",
    "    \n",
    "    nLayers = len(layer_dict.keys())\n",
    "    params = model.count_params()\n",
    "    hyperParams = 0\n",
    "    size_kb = 0\n",
    "    opt=\"sgd\"\n",
    "    \n",
    "    model_df = pd.DataFrame(columns=['name', 'layers', 'params', 'hyperParams',\n",
    "                                     'size_kb', 'filePath', 'optimizer'],\n",
    "                            data = [[modelName, nLayers, params, hyperParams,\n",
    "                                    size_kb, h5_path, opt]])\n",
    "    layer_df = pd.DataFrame(columns=['modelName', 'depth', 'type', 'params', 'filters', 'inputShape',\n",
    "                                     'outputShape','kernelShape', 'strides'],\n",
    "                            index=np.arange(nLayers))\n",
    "    layer_df.loc[:, 'modelName'] = modelName\n",
    "    depth=0\n",
    "    for key, val in layer_dict.items():\n",
    "        layer_df.loc[depth, 'depth'] = depth+1\n",
    "        layer_df.loc[depth, 'type'] = key\n",
    "        layer_df.loc[depth, 'params'] = model.layers[depth].count_params()\n",
    "        layer_df.loc[depth, 'inputShape'] = model.layers[depth].input_shape[1:]\n",
    "        layer_df.loc[depth, 'outputShape'] = model.layers[depth].output_shape[1:]\n",
    "        if (key == 'CONV_2D'):\n",
    "            layer_df.loc[depth, 'filters'] = val[0]\n",
    "            layer_df.loc[depth, 'kernelShape'] = val[1]\n",
    "            layer_df.loc[depth, 'strides'] = (1,1)\n",
    "        elif (key == 'POOL'):\n",
    "            layer_df.loc[depth, 'filters'] = 0\n",
    "            layer_df.loc[depth, 'kernelShape'] = val[0]\n",
    "            layer_df.loc[depth, 'strides'] = val[1]\n",
    "        depth += 1\n",
    "    #display(model_df)\n",
    "    #display(layer_df)\n",
    "    model_df.to_csv(os.path.join(out_dir, \"{}.csv\".format(modelName)),\n",
    "                    header=False)\n",
    "    layer_df.to_csv(os.path.join(out_dir, \"{}_layers.csv\".format(modelName)),\n",
    "                    header=False)\n",
    "    #model_df.iloc[0,:] = [modelName]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCNN(cnn, ep=10, b_size=128, modelName=\"newModel\"):\n",
    "    print(\"Training model {}...\".format(modelName))\n",
    "    hist = cnn.fit(X_train, y_train, batch_size=b_size, epochs=ep)\n",
    "    hist_df = pd.DataFrame(hist.history)\n",
    "    hist_df.to_csv(\"..\\\\..\\\\store\\\\train\\\\{}.csv\".format(modelName))\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 2.0967 - acc: 0.2489\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.9143 - acc: 0.3273\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.8351 - acc: 0.3617\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.7636 - acc: 0.3901\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6984 - acc: 0.4137\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.6381 - acc: 0.4343\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5877 - acc: 0.4512\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.5456 - acc: 0.4643\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5081 - acc: 0.4758\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.4727 - acc: 0.4874\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.1031 - acc: 0.2446\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.9168 - acc: 0.3283\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.8481 - acc: 0.3573\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 1.7930 - acc: 0.3805\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.7465 - acc: 0.3960\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.7051 - acc: 0.4111\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.6641 - acc: 0.4242\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 1.6248 - acc: 0.4353\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5905 - acc: 0.4478\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.5577 - acc: 0.4590\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\..\\\\store\\\\csv\\\\CIFAR_CNN_small.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-53608e73ee56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mhist1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"CIFAR_CNN_small\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mhist2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"CIFAR_CNN_small_2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mwriteModelData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_dict1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"CIFAR_CNN_small\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mwriteModelData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_dict2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"CIFAR_CNN_small_2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d9bb3eff3d3c>\u001b[0m in \u001b[0;36mwriteModelData\u001b[1;34m(model, layer_dict, modelName, out_dir)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m#display(layer_df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     model_df.to_csv(os.path.join(out_dir, \"{}.csv\".format(modelName)),\n\u001b[1;32m---> 39\u001b[1;33m                     header=False)\n\u001b[0m\u001b[0;32m     40\u001b[0m     layer_df.to_csv(os.path.join(out_dir, \"{}_layers.csv\".format(modelName)),\n\u001b[0;32m     41\u001b[0m                     header=False)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    135\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                                      compression=None)\n\u001b[0m\u001b[0;32m    137\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\..\\\\store\\\\csv\\\\CIFAR_CNN_small.csv'"
     ]
    }
   ],
   "source": [
    "input_shape = (32,32,3)\n",
    "\n",
    "layer_dict1 = {'CONV_2D' : [16, (3,3), input_shape, 'relu'],\n",
    "               'POOL'    : [(2,2), (2,2)],\n",
    "               'FLATTEN' : [],\n",
    "               'DENSE'   : [128, 'relu'],\n",
    "               'DENSE'   : [10, 'softmax']}\n",
    "\n",
    "layer_dict2 = {'CONV_2D' : [8, (3,3), input_shape, 'relu'],\n",
    "               'POOL'    : [(2,2), (2,2)],\n",
    "               'FLATTEN' : [],\n",
    "               'DENSE'   : [128, 'relu'],\n",
    "               'DENSE'   : [10, 'softmax']}\n",
    "\n",
    "cnn1 = makeCNN(layer_dict1)\n",
    "cnn2 = makeCNN(layer_dict2)\n",
    "#cnn1.summary()\n",
    "hist1 = trainCNN(cnn1, modelName=\"CIFAR_CNN_small\")\n",
    "hist2 = trainCNN(cnn2, modelName=\"CIFAR_CNN_small_2\")\n",
    "writeModelData(cnn1, layer_dict1, \"CIFAR_CNN_small\")\n",
    "writeModelData(cnn2, layer_dict2, \"CIFAR_CNN_small_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 1.0756 - acc: 0.7341\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3991 - acc: 0.8864\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.3494 - acc: 0.8990\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3277 - acc: 0.9051\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3143 - acc: 0.9091\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3037 - acc: 0.9118\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2950 - acc: 0.9147\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2874 - acc: 0.9160\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2811 - acc: 0.9193\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2744 - acc: 0.9209\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 1.1422 - acc: 0.6935\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4080 - acc: 0.8821\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3536 - acc: 0.8967\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3303 - acc: 0.9041\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3156 - acc: 0.9081\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3043 - acc: 0.9119\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2946 - acc: 0.9152\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2861 - acc: 0.9174\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2782 - acc: 0.9200\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2705 - acc: 0.9222\n"
     ]
    }
   ],
   "source": [
    "hist1 = trainCNN(cnn1)\n",
    "hist2 = trainCNN(cnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1_df = pd.DataFrame(hist1.history)\n",
    "hist2_df = pd.DataFrame(hist2.history)\n",
    "hist2_df.to_csv(\"MNIST_CNN_small.csv\")\n",
    "hist1_df.to_csv(\"MNIST_CNN_small_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeModelData(cnn1, layer_dict1, \"CIFAR_CNN_small\")\n",
    "writeModelData(cnn2, layer_dict2, \"CIFAR_CNN_small_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
