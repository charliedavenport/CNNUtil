{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n",
      "img data fmt:  channels_last\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, save_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.optimizers import SGD\n",
    "from IPython.display import display\n",
    "import keras.utils\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "print('img data fmt: ', K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "# convert target labels from scalars to an array of binary values\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# convert img data from ints in range [0,255] to floats in range [0,1] \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNN(layer_dict, opt=\"sgd\"):\n",
    "    cnn = Sequential()\n",
    "    for key, val in layer_dict.items():\n",
    "        if (key=='CONV_2D'):\n",
    "            cnn.add(Conv2D(filters=val[0], \n",
    "                           kernel_size=val[1], \n",
    "                           input_shape=val[2],\n",
    "                           activation=val[3]))\n",
    "        elif (key=='POOL'):\n",
    "            cnn.add(MaxPooling2D(pool_size=val[0],\n",
    "                                 strides=val[1]))\n",
    "        elif (key=='FLATTEN'):\n",
    "            cnn.add(Flatten())\n",
    "        elif (key=='DENSE'):\n",
    "            cnn.add(Dense(units=val[0],\n",
    "                          activation=val[1]))\n",
    "    \n",
    "    cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeModelData(model, layer_dict, modelName=\"new_model\", out_dir=\"..\\\\..\\\\store\\\\csv\"):\n",
    "    \n",
    "    h5_path = \"..\\\\..\\\\store\\\\saved_models\\\\{}.h5\".format(modelName)\n",
    "    model.save(h5_path)\n",
    "    \n",
    "    nLayers = len(layer_dict.keys())\n",
    "    params = model.count_params()\n",
    "    hyperParams = 0\n",
    "    size_kb = 0\n",
    "    opt=\"sgd\"\n",
    "    \n",
    "    model_df = pd.DataFrame(columns=['name', 'layers', 'params', 'hyperParams',\n",
    "                                     'size_kb', 'filePath', 'optimizer'],\n",
    "                            data = [[modelName, nLayers, params, hyperParams,\n",
    "                                    size_kb, h5_path, opt]])\n",
    "    layer_df = pd.DataFrame(columns=['modelName', 'depth', 'type', 'params', 'filters', 'inputShape',\n",
    "                                     'outputShape','kernelShape', 'strides'],\n",
    "                            index=np.arange(nLayers))\n",
    "    layer_df.loc[:, 'modelName'] = modelName\n",
    "    depth=0\n",
    "    for key, val in layer_dict.items():\n",
    "        layer_df.loc[depth, 'depth'] = depth+1\n",
    "        layer_df.loc[depth, 'type'] = key\n",
    "        layer_df.loc[depth, 'params'] = model.layers[depth].count_params()\n",
    "        layer_df.loc[depth, 'inputShape'] = model.layers[depth].input_shape[1:]\n",
    "        layer_df.loc[depth, 'outputShape'] = model.layers[depth].output_shape[1:]\n",
    "        if (key == 'CONV_2D'):\n",
    "            layer_df.loc[depth, 'filters'] = val[0]\n",
    "            layer_df.loc[depth, 'kernelShape'] = val[1]\n",
    "            layer_df.loc[depth, 'strides'] = (1,1)\n",
    "        elif (key == 'POOL'):\n",
    "            layer_df.loc[depth, 'filters'] = 0\n",
    "            layer_df.loc[depth, 'kernelShape'] = val[0]\n",
    "            layer_df.loc[depth, 'strides'] = val[1]\n",
    "        depth += 1\n",
    "    #display(model_df)\n",
    "    #display(layer_df)\n",
    "    model_df.to_csv(os.path.join(out_dir, \"{}.csv\".format(modelName)),\n",
    "                    header=False)\n",
    "    layer_df.to_csv(os.path.join(out_dir, \"{}_layers.csv\".format(modelName)),\n",
    "                    header=False)\n",
    "    #model_df.iloc[0,:] = [modelName]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28,28,1)\n",
    "\n",
    "layer_dict1 = {'CONV_2D' : [16, (3,3), input_shape, 'relu'],\n",
    "               'POOL'    : [(2,2), (2,2)],\n",
    "               'FLATTEN' : [],\n",
    "               'DENSE'   : [128, 'relu'],\n",
    "               'DENSE'   : [10, 'softmax']}\n",
    "\n",
    "layer_dict2 = {'CONV_2D' : [8, (3,3), input_shape, 'relu'],\n",
    "               'POOL'    : [(2,2), (2,2)],\n",
    "               'FLATTEN' : [],\n",
    "               'DENSE'   : [128, 'relu'],\n",
    "               'DENSE'   : [10, 'softmax']}\n",
    "\n",
    "cnn1 = makeCNN(layer_dict1)\n",
    "cnn2 = makeCNN(layer_dict2)\n",
    "#cnn1.summary()\n",
    "#hist1 = trainCNN(cnn1)\n",
    "#writeModelData(cnn1, layer_dict1, \"MNIST_CNN_small\")\n",
    "#writeModelData(cnn2, layer_dict2, \"MNIST_CNN_small_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCNN(cnn, ep=10, b_size=128, dataset='MNIST', modelName=\"newModel\"):\n",
    "    hist = cnn.fit(X_train, y_train, batch_size=b_size, epochs=ep)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 1.0756 - acc: 0.7341\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3991 - acc: 0.8864\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.3494 - acc: 0.8990\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3277 - acc: 0.9051\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3143 - acc: 0.9091\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3037 - acc: 0.9118\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2950 - acc: 0.9147\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2874 - acc: 0.9160\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2811 - acc: 0.9193\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2744 - acc: 0.9209\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 1.1422 - acc: 0.6935\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4080 - acc: 0.8821\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3536 - acc: 0.8967\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3303 - acc: 0.9041\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3156 - acc: 0.9081\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3043 - acc: 0.9119\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2946 - acc: 0.9152\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2861 - acc: 0.9174\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2782 - acc: 0.9200\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2705 - acc: 0.9222\n"
     ]
    }
   ],
   "source": [
    "hist1 = trainCNN(cnn1)\n",
    "hist2 = trainCNN(cnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1_df = pd.DataFrame(hist1.history)\n",
    "hist2_df = pd.DataFrame(hist2.history)\n",
    "hist2_df.to_csv(\"MNIST_CNN_small.csv\")\n",
    "hist1_df.to_csv(\"MNIST_CNN_small_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cnn1, cnn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
